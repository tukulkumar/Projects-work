{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nums = Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var nums = 1  to 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numsRDD = ParallelCollectionRDD[0] at parallelize at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at <console>:29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var numsRDD = sc.parallelize(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numsRDD.partitions.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 6) / 6]"
     ]
    }
   ],
   "source": [
    "numsRDD.saveAsTextFile(\"somedir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1], [2, 3], [4, 5], [6], [7, 8], [9, 10]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numsRDD.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kvrdd = MapPartitionsRDD[3] at map at <console>:31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[3] at map at <console>:31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var kvrdd = numsRDD.map((_, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,1), (2,1), (3,1), (4,1), (5,1), (6,1), (7,1), (8,1), (9,1), (10,1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.HashPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prdd = ShuffledRDD[4] at partitionBy at <console>:34\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[4] at partitionBy at <console>:34"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var prdd = kvrdd.partitionBy(new HashPartitioner(3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(3,1), (6,1), (9,1)], [(1,1), (4,1), (7,1), (10,1)], [(2,1), (5,1), (8,1)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words = ParallelCollectionRDD[6] at parallelize at <console>:29\n",
       "wordsTups = MapPartitionsRDD[7] at map at <console>:30\n",
       "output = ShuffledRDD[10] at partitionBy at <console>:31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[[(is,1), (a,1), (cat,1), (is,1), (a,1), (cat,1), (eats,1)], [(this,1), (there,1), (rat,1), (rat,1)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.RangePartitioner\n",
    "var words = sc.parallelize(Array(\"this\", \"is\", \"a\", \"cat\", \"there\", \"is\", \"a\", \"rat\", \"cat\", \"eats\", \"rat\"), 2)\n",
    "var wordsTups = words.map((_, 1))\n",
    "var output = wordsTups.partitionBy(new RangePartitioner(2, wordsTups))\n",
    "output.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.saveAsTextFile(\"myoutput_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "file = /data/mr/wordcount/input/ MapPartitionsRDD[1] at textFile at <console>:27\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/data/mr/wordcount/input/ MapPartitionsRDD[1] at textFile at <console>:27"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var file = sc.textFile(\"/data/mr/wordcount/input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numBlankLines = 0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there were two deprecation warnings; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var numBlankLines = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toWords: (line: String)Array[String]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def toWords(line:String): Array[String] = {    \n",
    "  if(line.length == 0) {numBlankLines += 1}    \n",
    "  return line.split(\" \");    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 0:===================>                                       (1 + 2) / 3]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "words = MapPartitionsRDD[2] at flatMap at <console>:33\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[2] at flatMap at <console>:33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var words = file.flatMap(toWords)\n",
    "words.saveAsTextFile(\"words3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank lines: 24858"
     ]
    }
   ],
   "source": [
    "printf(\"Blank lines: %d\", numBlankLines.value)    \n",
    "//Blank lines: 24858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class MyComplex\n",
       "defined class ComplexAccumulatorV1\n",
       "vecAccum = MyComplex@26ff3e45\n",
       "myrdd = ParallelCollectionRDD[4] at parallelize at <console>:42\n",
       "myrdd1 = MapPartitionsRDD[5] at map at <console>:47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there were two deprecation warnings; re-run with -deprecation for details\n",
       "myfunc: (x: Int)Int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyComplex(var x: Int, var y: Int) extends Serializable{\n",
    "def reset(): Unit = {\n",
    "    x = 0\n",
    "    y = 0\n",
    "}\n",
    "def add(p:MyComplex): MyComplex = {\n",
    "    x = x + p.x\n",
    "    y = y + p.y\n",
    "    return this\n",
    "}\n",
    "}\n",
    "\n",
    "import org.apache.spark.AccumulatorParam\n",
    "class ComplexAccumulatorV1 extends AccumulatorParam[MyComplex] {\n",
    "\n",
    "    def zero(initialVal: MyComplex): MyComplex = {\n",
    "        return initialVal\n",
    "    }\n",
    "\n",
    "    def addInPlace(v1: MyComplex, v2: MyComplex): MyComplex = {\n",
    "        v1.add(v2)\n",
    "        return v1;\n",
    "    }\n",
    "}\n",
    "\n",
    "val vecAccum = sc.accumulator(new MyComplex(0,0))(new ComplexAccumulatorV1)\n",
    "\n",
    "var myrdd = sc.parallelize(Array(1,2,3))\n",
    "def myfunc(x:Int):Int = {\n",
    "    vecAccum += new MyComplex(x, x)\n",
    "    return x * 3\n",
    "}\n",
    "var myrdd1 = myrdd.map(myfunc)\n",
    "myrdd1.collect()\n",
    "vecAccum.value.x\n",
    "vecAccum.value.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
