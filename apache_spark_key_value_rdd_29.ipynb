{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputdata = List((1,2), (1,3), (2,4))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List((1,2), (1,3), (2,4))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var inputdata = List((1,2),(1,3),(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kvrdd = ParallelCollectionRDD[0] at parallelize at <console>:29\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at <console>:29"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var kvrdd = sc.parallelize(inputdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 6) / 6]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,2), (1,3), (2,4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kvrdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "out = ShuffledRDD[2] at reduceByKey at <console>:31\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[2] at reduceByKey at <console>:31"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val out = kvrdd.reduceByKey((a,b)=>a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,5), (2,4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: ';' expected but double literal found.\n",
       "hadoop fs -get /data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/FlumeData.1367523670393.gz\n",
       "                                                                                   ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadoop fs -get /data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/FlumeData.1367523670393.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.{ByteArrayOutputStream, ByteArrayInputStream}\n",
    "import java.util.zip.{GZIPOutputStream, GZIPInputStream}\n",
    "import scala.collection.mutable.ArrayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets_raw = /data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/ BinaryFileRDD[3] at binaryFiles at <console>:30\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "/data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/ BinaryFileRDD[3] at binaryFiles at <console>:30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var tweets_raw = sc.binaryFiles(\"/data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hdfs://cxln1.c.thelab-240901.internal:8020/data/SentimentFiles/SentimentFiles/upload/data/tweets_raw/FlumeData.1367523670394.gz"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_raw.take(2)(0)._1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.DataInputStream\n",
    "import org.apache.spark.input.PortableDataStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_length: (compressed: org.apache.spark.input.PortableDataStream)Int\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_length(compressed: PortableDataStream): Int = {\n",
    "    var compressedis:DataInputStream = null\n",
    "    try{\n",
    "        var compressedis = compressed.open()\n",
    "\n",
    "        val gzipInputStream = new GZIPInputStream(compressedis)\n",
    "        var output = 0\n",
    "        var totalByteCount = 0\n",
    "        val bytes = new Array[Byte](1024)\n",
    "        while (gzipInputStream.available() == 1) {\n",
    "          val byteCount = gzipInputStream.read(bytes)\n",
    "          if (byteCount > 0) {\n",
    "            var lb = bytes.take(byteCount)\n",
    "            output = output + lb.length\n",
    "            totalByteCount += byteCount\n",
    "          }\n",
    "        }\n",
    "        return output;\n",
    "    }\n",
    "    finally{\n",
    "        if(compressedis != null)\n",
    "            compressedis.close()\n",
    "    }  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "decompressed_tweets_lengths = MapPartitionsRDD[4] at mapValues at <console>:36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[4] at mapValues at <console>:36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var decompressed_tweets_lengths = tweets_raw.mapValues(t => count_length(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stage 4:=============================>                             (1 + 1) / 2]"
     ]
    }
   ],
   "source": [
    "decompressed_tweets_lengths.saveAsTextFile(\"onlytweets_length_after_decompressing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
